{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9593f23-5c3b-424e-b37b-47973fb5f13a",
   "metadata": {},
   "source": [
    "### 参考\n",
    "1. [Spark_SQL_cheatsheet_code.ipynb](https://github.com/ShowMeAI-Hub/awesome-AI-cheatsheets/blob/main/Spark/Spark_SQL_cheatsheet_code.ipynb)， 镜像在gitee [ShowMeAI-Hub--awesome-AI-cheatsheets.git](https://gitee.com/mirrr/ShowMeAI-Hub--awesome-AI-cheatsheets/tree/main/Spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bb2800-6bb2-4dfe-b3fe-e2bdfa263753",
   "metadata": {},
   "source": [
    "### 环境安装\n",
    "\n",
    "https://cdn.azul.com/zulu/bin/zulu8.76.0.17-ca-jdk8.0.402-linux_x64.tar.gz\n",
    "\n",
    "https://archive.apache.org/dist/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4438b3-79fd-4178-a338-7111e5d81050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024年 03月 25日 星期一 20:06:38 CST\n",
      "/fridaAnlzAp/analyze_by_spark_GraphFrame\n",
      "/app/Miniconda3-py37_4.12.0/bin/python\n",
      "/app/Miniconda3-py37_4.12.0/bin/pip\n",
      "/app/zulu8.76.0.17-ca-jdk8.0.402-linux_x64: directory\n",
      "/app/spark-2.4.8-bin-hadoop2.7:             directory\n",
      "3af9ae26e91360c0f39a5647d9279715  /app/pack/spark-2.4.8-bin-hadoop2.7.tgz\n",
      "3d8073a1e7bc71a0c53bbbbad590dad2  /app/pack/zulu8.76.0.17-ca-jdk8.0.402-linux_x64.tar.gz\n",
      "-rwxrwxrwx 1 z z 263M  3月 24 16:57 /fridaAnlzAp/frida_js/frida-trace-out-RunBuszJs-1711270533.log\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting findspark\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a4/cb/7d2bb508f4ca00a043fd53e8156c11767799d3f534bf451a0942211d5def/findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "date && pwd\n",
    "\n",
    "which python\n",
    "which pip\n",
    "\n",
    "file /app/zulu8.76.0.17-ca-jdk8.0.402-linux_x64 /app/spark-2.4.8-bin-hadoop2.7\n",
    "md5sum /app/pack/spark-2.4.8-bin-hadoop2.7.tgz /app/pack/zulu8.76.0.17-ca-jdk8.0.402-linux_x64.tar.gz\n",
    "\n",
    "ls -lh /fridaAnlzAp/frida_js/*RunBuszJs*.log\n",
    "\n",
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca528c7b-c1b5-4e82-a911-6d9fd06540d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"]=\"/app/zulu8.76.0.17-ca-jdk8.0.402-linux_x64\"\n",
    "# os.environ[\"SPARK_HOME\"]=\"/app/spark-2.4.8-bin-hadoop2.7\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ff4476-a724-4ec9-a6a3-84928a55c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(spark_home=\"/app/spark-2.4.8-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "261fa75f-1cd1-4d68-afeb-077bb9d0bae5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mspark_home\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpython_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0medit_rc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0medit_profile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Make pyspark importable.\n",
       "\n",
       "Sets environment variables and adds dependencies to sys.path.\n",
       "If no Spark location is provided, will try to find an installation.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "spark_home : str, optional, default = None\n",
       "    Path to Spark installation, will try to find automatically\n",
       "    if not provided.\n",
       "python_path : str, optional, default = None\n",
       "    Path to Python for Spark workers (PYSPARK_PYTHON),\n",
       "    will use the currently running Python if not provided.\n",
       "edit_rc : bool, optional, default = False\n",
       "    Whether to attempt to persist changes by appending to shell\n",
       "    config.\n",
       "edit_profile : bool, optional, default = False\n",
       "    Whether to create an IPython startup file to automatically\n",
       "    configure and import pyspark.\n",
       "\u001b[0;31mFile:\u001b[0m      /app/Miniconda3-py310_22.11.1-1/lib/python3.10/site-packages/findspark.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "findspark.init?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d44251-7a74-45d3-9021-b597e1af3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#必须用py3.7 , 否则 这一行报错 TypeError: 'bytes' object cannot be interpreted as an integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cabaf60",
   "metadata": {},
   "source": [
    "SparkSession 用于创建数据帧，将数据帧注册为表，执行 SQL 查询，缓存表及读取 Parquet 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1e7564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 20:16:18 WARN Utils: Your hostname, mchr resolves to a loopback address: 127.0.1.1; using 10.0.4.23 instead (on interface wlo1)\n",
      "24/03/25 20:16:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/03/25 20:16:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "       .builder \\\n",
    "       .appName(\"analyze_by_spark_GraphFrame\") \\\n",
    "       .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b04b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0417e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "728dc059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-25 20:16:51--  https://github.com/awesome-AI-cheatsheets/tree/main/Spark/data/people.txt\r\n",
      "正在解析主机 github.com (github.com)... 10.0.4.23\r\n",
      "正在连接 github.com (github.com)|10.0.4.23|:443... 失败：连接被拒绝。\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/awesome-AI-cheatsheets/tree/main/Spark/data/people.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69d844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
